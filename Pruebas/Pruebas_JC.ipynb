{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de n-gramas para determinar la polaridad del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrategia\n",
    "\n",
    "1. Elegir el modelo de n-gramas.\n",
    "\n",
    "2. Crear un grupo de entrenamiento (85%) y otro de prueba (15%).\n",
    "\n",
    "**Conjunto de entrenamiento:** \n",
    "\n",
    "3. Dentro del grupo de entrenamiento, crear dos subgrupos; el primero con las opiniones positivas y el segundo con las opiniones negativas.\n",
    "\n",
    "4. Obtener los n-gramas de cada subgrupo. \n",
    "\n",
    "5. En una estructura tipo diccionario, a cada n-grama se le asigna un número entero que representa la cantidad de veces que dicho n-grama apareció en el subgrupo. No obstante, si el grupo es el negativo, entonces el número será negativo. En cambio, si el grupo es el positivo, entonces el número será positivo. \n",
    "\n",
    "6. Con los n-gramas que están presentes en ambos subgrupos, se tendrá que restar sus respectivos valores asociados y el resultado será el valor asociado final de dicho n-grama.\n",
    "\n",
    "**Conjunto de prueba:** \n",
    " \n",
    "7. Para que el modelo asigne la polaridad a un texto del conjunto prueba, primero tendrá que obtener los n-gramas de dicho texto. \n",
    "\n",
    "8. A cada n-grama le asignará su valor asociado en el conjunto de entrenamiento.\n",
    "\n",
    "9. Los n-gramas que no estén presentes en el conjunto de entrenamiento serán considerados <UNKNOWNS> (debatible).\n",
    "\n",
    "10. Se realizará la suma de todos los valores asociados a los n-gramas del texto y el signo del resultado determinará la polaridad de dicho texto. \n",
    "\n",
    "11. Evaluar desempeño del modelo con F1-score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jcbar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jcbar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar recursos necesarios de nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para cargar y preparar los datos\n",
    "\n",
    "**Con esta función:**\n",
    "\n",
    "1. Se cargan los datos desde un archivo CSV\n",
    "2. Se concatenan los strings que se encuentran en la columna \"Opinion\" y en la columna \"Title\"\n",
    "3. Se eliminan las filas que contienen nan's\n",
    "4. Se separan los datos en un conjunto de entrenamiento (85%) y uno de prueba (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar y preparar los datos\n",
    "def load_and_prepare_data(file_path, test_size=0.15):\n",
    "    \"\"\"\n",
    "    Carga el contenido de un archivo CSV y lo divide en conjuntos de prueba y entrenamiento.\n",
    "    \n",
    "    file_path: Ruta al archivo CSV\n",
    "    \n",
    "    return: Un DataFrame con los datos de entrenamiento y otro con los datos de prueba.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)                                   # Cargar CSV\n",
    "    df['Text'] = df['Title'] + \" \" + df['Opinion']                # Concatenar opinión y título\n",
    "    df = df.dropna()                                              # Eliminar filas con nan's \n",
    "    \n",
    "    return train_test_split(df, test_size=test_size, random_state=42)  # Divir datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para limpiar el texto \n",
    "\n",
    "**Con esta función:**\n",
    "\n",
    "1. De manera opcional, se pueden eliminar los signos de puntuación\n",
    "2. De manera opcional,\n",
    "\n",
    "    2.1. Todo el texto se pasa a mínusculas \n",
    "\n",
    "    2.2. Se realiza una tokenización del texto\n",
    "    \n",
    "    2.3  Se une el texto separando los tokens por espacios, ignorando las stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para eliminar signos de puntuación y stop words\n",
    "def clean_text(text, remove_punctuation=True, remove_stopwords=True):\n",
    "    \"\"\"\n",
    "    Limpia un texto (string) eliminando signos de puntuación y/o stopwords.\n",
    "    \n",
    "    text: Texto en formato string\n",
    "    remove_punctuation: Booleano que determina si se elimina o no los signos de puntuación\n",
    "    remove_stopword: Booleano que determina si se elimina o no las stopwords\n",
    "    \n",
    "    return: Texto (string) limpio.\n",
    "    \"\"\"\n",
    "    if remove_punctuation:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))  # Eliminar los signos de puntuación: !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('spanish'))  # Extraer stopwords\n",
    "        text = ' '.join([word for word in word_tokenize(text.lower()) if word not in stop_words])  # Tokenizar ignorando las stop-words\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para obtener los k-skip-n-gramas\n",
    "\n",
    "**Con esta función:**\n",
    "\n",
    "1. Se realiza una tokenización del texto\n",
    "2. Se obtienen los k-skip-n-gramas del texto, con una k y n establecidas por el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener n-gramas\n",
    "def get_ngrams(text, n=2, skip=0):\n",
    "    \"\"\"\n",
    "    Genera n-gramas (o skip-gramas si skip > 0) a partir de un texto.\n",
    "    \n",
    "    text: Texto a partir del cual se extraerán los n-gramas (o skip-gramas)\n",
    "    n: Número de palabras en el n-grama\n",
    "    skip: Número de palabras a saltar (solo para skip-gramas)\n",
    "    \n",
    "    return: Lista de n-gramas\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text.lower())  # Tokenizar el texto todo en mínusculas\n",
    "    \n",
    "    # Obterner n-gramas\n",
    "    if skip == 0:\n",
    "        return list(ngrams(tokens, n))\n",
    "    \n",
    "    # Obtener k-skip-n-gramas\n",
    "    else:\n",
    "        return list(nltk.skipgrams(tokens, n, skip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para obtener la frecuencia de aparición de n-gramas en un corpus\n",
    "\n",
    "**Con esta función:**\n",
    "\n",
    "1. Se obtienen los n-gramas de todos los textos de un corpus dado utilizando *get_ngrams*\n",
    "2. Se cuenta la cantidad de veces que aparece cada n-grama en el corpus\n",
    "3. Cada vez que un n-grama aparece en el corpus a su frecuencia de aparición se le suma el valor \"weight\" pre-determinado por el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular las frecuencias de los n-gramas\n",
    "def calculate_ngram_frequencies(texts, n=2, skip=0, weight=1):\n",
    "    \"\"\"\n",
    "    Genera n-gramas (o skip-gramas si skip > 0) a partir de un conjunto de textos y calcula su frecuencia de aparición con base en weight.\n",
    "    \n",
    "    texts: Conjunto de textos de los que se obtendrán los n-gramas (o skip-gramas)\n",
    "    n: Número de palabras en el n-grama\n",
    "    skip: Número de palabras a saltar (solo para skip-gramas)\n",
    "    weight: Cada aparición de un n-grama dado contribuirá con un valor de weight a su frecuencias\n",
    "    \n",
    "    return: defaultdict con la frecuencia de aparición de cada n-grama. \n",
    "    \"\"\"\n",
    "\n",
    "    ngram_values = defaultdict(int)  # Definir un defaultdict vacío\n",
    "    \n",
    "    # Iterar sobre todos los textos\n",
    "    for text in texts:\n",
    "        ngrams = get_ngrams(text, n, skip)  # Obtener n-gramas (o skip-gramas)\n",
    "        \n",
    "        # Iterar sobre todos los n-gramas\n",
    "        for ngram in ngrams:\n",
    "            ngram_values[ngram] += weight  # Sumar el valor weight a la frecuencia de cada n-grama cada vez que aparezca\n",
    "    \n",
    "    return ngram_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para realizar el cálculo de la frecuencia de aparición de cada n-grama utilizando un valor de weight específico\n",
    "\n",
    "**Con esta función:**\n",
    "\n",
    "1. Se utiliza *calculate_ngram_frequencies*  para ajustar el valor de weight, aplicando el hecho de que los n-gramas apareciendo en textos negativos reciben un valor de weight negativo y los n-gramas apareciendo en textos positivos reciben un valor positivo.\n",
    "2. Además, dado el desbalance de las clases (solo el 5% son textos negativos), de manera opcional puede aplicarse un weight como sigue:\n",
    "\n",
    "    weight= 1/len(textos_positivos) para los n-gramas apareciendo en textos positivos\n",
    "    \n",
    "    weight= -1/len(textos_negativos) para los n-gramas apareciendo en textos negativos \n",
    "\n",
    "\n",
    "3. Independientemente de los valores de weight utilizados, se suman las frecuencias de aparición de los n-gramas en el grupo positivo y negativo, dando como resultado una frecuencia neta para cada n-grama. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para reponderar las clases\n",
    "def apply_class_weighting(positive_texts, negative_texts, n=2, skip=0, apply_weighting=True):\n",
    "    \"\"\"\n",
    "    Realiza una re-pondercación de la frecuencia de aparición de cada n-grama dependiendo del grupo al que pertenece.\n",
    "    \n",
    "    positive_text: Textos calificados como positivos (Label = 1)\n",
    "    negative_text: Textos calificados como negativos (Label = 0)\n",
    "    n: Número de palabras en el n-grama\n",
    "    skip: Número de palabras a saltar (solo para skip-gramas)\n",
    "    apply_weighting: Booleano que determina si se desea ponderar las frecuencias de aparición de los n-gramas con base en el desbalance de clases\n",
    "    \n",
    "    return: defaultdict con la frecuencia de aparición re-ponderada de los n-gramas\n",
    "    \"\"\"\n",
    "    \n",
    "    num_positive = len(positive_texts)  # Cantidad de textos clasificados como positivos\n",
    "    num_negative = len(negative_texts)  # Cantidad de textos clasificados como negativos\n",
    "    \n",
    "    weight_positive = 1 / num_positive if apply_weighting else 1  # Peso que tendrá la aparición de un n-grama en el grupo positivo\n",
    "    weight_negative = 1 / num_negative if apply_weighting else 1  # Peso que tendrá la aparición de un n-grama en el grupo negativo\n",
    "    \n",
    "    # Calcular frecuencias de aparición en los grupos positivo y negativo con sus respectivos pesos\n",
    "    positive_ngram_values = calculate_ngram_frequencies(positive_texts, n, skip, weight_positive)\n",
    "    negative_ngram_values = calculate_ngram_frequencies(negative_texts, n, skip, -weight_negative)\n",
    "    \n",
    "    # Combinar n-gramas de ambos grupos sumando sus frecuencias respectivas\n",
    "    combined_ngram_values = defaultdict(int, positive_ngram_values)\n",
    "    for ngram, value in negative_ngram_values.items():\n",
    "        combined_ngram_values[ngram] += value\n",
    "    \n",
    "    return combined_ngram_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para calcular la suma de las frecuencias netas de los n-gramas que componen a un texto\n",
    "\n",
    "**Con esta función:** \n",
    "\n",
    "1. Se obtienen los n-gramas de un texto con *get_ngrams*\n",
    "2. Cada n-grama se asocia con su valor de frecuencia neta calculado a partir de un weight y de su frecuencia de aparición en el grupo positivo y negativo \n",
    "3. Se suman las frecuencias netas de los n-gramas que componen al texto  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la polaridad de un texto\n",
    "def sum_net_frequencies(text, ngram_values, n=2, skip=0):\n",
    "    \"\"\"\n",
    "    Obtiene los n-gramas (o skip-gramas sin skip > 0) de un texto y suma sus valores de frecuencia asociados. \n",
    "    \n",
    "    text: Texto del que se obtendrán los n-gramas (o skip-gramas)\n",
    "    ngram_values: defaultdict con los ngramas y sus valores de frecuencia neta respectivos \n",
    "    n: Número de palabras en el n-grama\n",
    "    skip: Número de palabras a saltar (solo para skip-gramas)\n",
    "\n",
    "    return: Suma total de los valores de frecuencias de todos los n-gramas que componen al texto\n",
    "    \"\"\"\n",
    "    # Obtener n-gramas del texto\n",
    "    ngrams = get_ngrams(text, n, skip)\n",
    "\n",
    "    # Calcular la suma de los valores de frecuencia asociados a los n-gramas\n",
    "    return sum(ngram_values[ngram] for ngram in ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para predecir la polaridad de un texto\n",
    "\n",
    "**Con esta función:** \n",
    "\n",
    "1. Se determina la polaridad del texto a partir del output de *sum_net_frequencies* \n",
    "\n",
    "    Si el signo del output es negativo, entonces es un texto negativo\n",
    "\n",
    "    Si el signo del output es positivo, entonces es un texto positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir la polaridad en el conjunto de prueba\n",
    "def predict_polarity(test_data, ngram_values, n=2, skip=0):\n",
    "    \"\"\"\n",
    "    Determina la polaridad positiva/negativa de una serie de textos con base en el signo de la suma de la frecuencia neta de los n-gramas que componen a dichos textos. \n",
    "    \n",
    "    test_data: Textos de los que se obtendrá su polaridad\n",
    "    ngram_values: defaultdict con los ngramas y sus valores de frecuencia neta respectivos \n",
    "    n: Número de palabras en el n-grama\n",
    "    skip: Número de palabras a saltar (solo para skip-gramas)\n",
    "\n",
    "    return: 1 si la polaridad del texto es positiva y 0 si la polaridad es negativa\n",
    "    \"\"\"\n",
    "    return [1 if sum_net_frequencies(text, ngram_values, n, skip) > 0 else 0 for text in test_data['Text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para realizar todo un experimento con un modelo de n-grama dado\n",
    "\n",
    "**Con esta función:** \n",
    "\n",
    "1. Se cargan y preparan los datos *load_and_prepare_data*, generando un corpus de entrenamiento y uno de prueba\n",
    "2. De manera opcional, se remueven los signos de puntuación de los textos con *clean_data*\n",
    "3. De manera opcional, se remueven las stopwords de los textos con *clean_data*\n",
    "4. Con los textos de entrenamiento, se obtienen las frecuencias neta de los k-skip-n-gramas (con k y n determinados por el usuario) con base en su frecuencia de aparición en los textos positivos y negativos utilizando *apply_class_weighting*\n",
    "\n",
    "\n",
    "     De manera opcional, se puede utilizar los valores de weight para abordar el problema del desbalance de clases\n",
    "\n",
    "\n",
    "5. Con cada texto de prueba, se suman las frecuencias netas de sus k-skip-n-gramas y se predice su polaridad\n",
    "6. Se mide el desempeño del modelo por medio de la F1-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función principal para entrenar y evaluar el modelo\n",
    "def run_experiment(file_path, n=2, skip=0, remove_punctuation=True, remove_stopwords=True, apply_weighting=True):\n",
    "    \"\"\"\n",
    "    Hace uso de las funciones definidas anteriormente para evaluar el desempeño de un modelo de n-gramas prediciendo la polaridad del conjunto de textos de prueba.\n",
    "    \n",
    "    file_path: Ruta al archivo CSV con los datos\n",
    "    n: Número de palabras en el n-grama\n",
    "    skip: Número de palabras a saltar (solo para skip-gramas)\n",
    "    remove_punctuation: Booleano que determina si se elimina o no los signos de puntuación\n",
    "    remove_stopword: Booleano que determina si se elimina o no las stopwords\n",
    "    apply_weighting: Booleano que determina si se desea ponderar las frecuencias de aparición de los n-gramas con base en el desbalance de clases\n",
    "    \n",
    "    return: 1 si la polaridad del texto es positiva y 0 si la polaridad es negativa\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cargar datos de entrenamiento y prueba\n",
    "    train_data, test_data = load_and_prepare_data(file_path)\n",
    "    \n",
    "    # Limpiar datos (eliminar signos de puntuación y stopwords)\n",
    "    train_data['Text'] = train_data['Text'].apply(lambda x: clean_text(x, remove_punctuation, remove_stopwords))\n",
    "    test_data['Text'] = test_data['Text'].apply(lambda x: clean_text(x, remove_punctuation, remove_stopwords))\n",
    "    \n",
    "    # Separar textos positivos y negativos\n",
    "    positive_texts = train_data[train_data['Label'] == 1]['Text']\n",
    "    negative_texts = train_data[train_data['Label'] == 0]['Text']\n",
    "    \n",
    "    \n",
    "    # Obtener las frecuencias netas de los n-gramas en el corpus\n",
    "    ngram_values = apply_class_weighting(positive_texts, negative_texts, n, skip, apply_weighting)\n",
    "    # Predecir la polaridad de los textos\n",
    "    y_pred = predict_polarity(test_data, ngram_values, n, skip)\n",
    "    \n",
    "    # Evaluar el desempeño del modelo con f1-score\n",
    "    return f1_score(test_data['Label'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para realizar un Grid Search sobre los parámetros de la función *run_experiment*\n",
    "\n",
    "**Con esta función:** \n",
    "\n",
    "1. Se ejecuta *run_experiment* con todas las combinaciones de valores posibles para sus parámetros\n",
    "2. En cada caso se cálcula el valor de F1-score \n",
    "3. Se guarda el valor más alto de F1-score y sus los valores respectivos de los parámetros de *run_experiment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Manual\n",
    "def grid_search(file_path):\n",
    "    \"\"\"\n",
    "    Realizar un grid search sobre los parámetros de la función run_experiment.\n",
    "    Imprime el F1-score y los valores de los parámetros de run_experiment asociados. \n",
    "    \n",
    "    file_path: Ruta al archivo CSV con los datos\n",
    "\n",
    "    return: None\n",
    "    \"\"\"\n",
    "    # Posibles valores de los n-gramas (nos limitamos a uni, bi y trigramas)\n",
    "    n_values = [1, 2, 3]\n",
    "    # Posibles valores de k en k-skip-n-gramas (nos limitamos a saltos de 1 y 2 tokens)\n",
    "    skip_values = [0, 1, 2]\n",
    "    # Posibles valores de los parámetros booleanos\n",
    "    remove_punctuation_options = [True, False]\n",
    "    remove_stopwords_options = [True, False]\n",
    "    apply_weighting_options = [True, False]\n",
    "    \n",
    "    best_f1 = 0       # Variable para almacenar el valor más alto de F1-score\n",
    "    best_params = {}  # Diccionario vacío para almacenar los mejores valores de los parámetros\n",
    "\n",
    "    # Iteramos sorbre los posibles valores de los parámetros de run_experiment\n",
    "    for n in n_values:\n",
    "        for skip in skip_values:\n",
    "            # Omitimos los casos en los que n==1 y skip > 0\n",
    "            if n == 1 and skip > 0:\n",
    "                continue\n",
    "            for remove_punctuation in remove_punctuation_options:\n",
    "                for remove_stopwords in remove_stopwords_options:\n",
    "                    for apply_weighting in apply_weighting_options:\n",
    "                        \n",
    "                        # Ejecutamos run_experiment con un set de valores en sus parámetros\n",
    "                        f1 = run_experiment(\n",
    "                            file_path,\n",
    "                            n=n,\n",
    "                            skip=skip,\n",
    "                            remove_punctuation=remove_punctuation,\n",
    "                            remove_stopwords=remove_stopwords,\n",
    "                            apply_weighting=apply_weighting\n",
    "                        )\n",
    "                        print(f\"F1-score: {f1:.4f} | Params: n={n}, skip={skip}, remove_punctuation={remove_punctuation}, remove_stopwords={remove_stopwords}, apply_weighting={apply_weighting}\")\n",
    "                        \n",
    "                        # En caso de que el valor actual de f1 sea mayor que el de best_f1, reemplazamos el valor de esta última\n",
    "                        if f1 > best_f1:\n",
    "                            best_f1 = f1\n",
    "                            best_params = {\n",
    "                                'n': n,\n",
    "                                'skip': skip,\n",
    "                                'remove_punctuation': remove_punctuation,\n",
    "                                'remove_stopwords': remove_stopwords,\n",
    "                                'apply_weighting': apply_weighting\n",
    "                            }\n",
    "    \n",
    "    # Imprimimos el valor más alto de F1 y los valores respectivos de los parámetros de run_experiment\n",
    "    print(\"\\nBest F1-score:\", best_f1)\n",
    "    print(\"Best Parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.7851 | Params: n=1, skip=0, remove_punctuation=True, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=1, skip=0, remove_punctuation=True, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.0982 | Params: n=1, skip=0, remove_punctuation=True, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=1, skip=0, remove_punctuation=True, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.0219 | Params: n=1, skip=0, remove_punctuation=False, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=1, skip=0, remove_punctuation=False, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.0000 | Params: n=1, skip=0, remove_punctuation=False, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=1, skip=0, remove_punctuation=False, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.8588 | Params: n=2, skip=0, remove_punctuation=True, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8989 | Params: n=2, skip=0, remove_punctuation=True, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.7840 | Params: n=2, skip=0, remove_punctuation=True, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8994 | Params: n=2, skip=0, remove_punctuation=True, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.8814 | Params: n=2, skip=0, remove_punctuation=False, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=2, skip=0, remove_punctuation=False, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.8037 | Params: n=2, skip=0, remove_punctuation=False, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=2, skip=0, remove_punctuation=False, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.8627 | Params: n=2, skip=1, remove_punctuation=True, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.9066 | Params: n=2, skip=1, remove_punctuation=True, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.7634 | Params: n=2, skip=1, remove_punctuation=True, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8994 | Params: n=2, skip=1, remove_punctuation=True, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.7186 | Params: n=2, skip=1, remove_punctuation=False, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=2, skip=1, remove_punctuation=False, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.7911 | Params: n=2, skip=1, remove_punctuation=False, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=2, skip=1, remove_punctuation=False, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.8596 | Params: n=2, skip=2, remove_punctuation=True, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.9060 | Params: n=2, skip=2, remove_punctuation=True, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.7344 | Params: n=2, skip=2, remove_punctuation=True, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8994 | Params: n=2, skip=2, remove_punctuation=True, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.7033 | Params: n=2, skip=2, remove_punctuation=False, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=2, skip=2, remove_punctuation=False, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.7729 | Params: n=2, skip=2, remove_punctuation=False, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=2, skip=2, remove_punctuation=False, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.6497 | Params: n=3, skip=0, remove_punctuation=True, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.6957 | Params: n=3, skip=0, remove_punctuation=True, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.8358 | Params: n=3, skip=0, remove_punctuation=True, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8992 | Params: n=3, skip=0, remove_punctuation=True, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.8461 | Params: n=3, skip=0, remove_punctuation=False, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8986 | Params: n=3, skip=0, remove_punctuation=False, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.8630 | Params: n=3, skip=0, remove_punctuation=False, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.9000 | Params: n=3, skip=0, remove_punctuation=False, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.7180 | Params: n=3, skip=1, remove_punctuation=True, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.7873 | Params: n=3, skip=1, remove_punctuation=True, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.8469 | Params: n=3, skip=1, remove_punctuation=True, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8998 | Params: n=3, skip=1, remove_punctuation=True, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.7679 | Params: n=3, skip=1, remove_punctuation=False, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8983 | Params: n=3, skip=1, remove_punctuation=False, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.8787 | Params: n=3, skip=1, remove_punctuation=False, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=3, skip=1, remove_punctuation=False, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.7572 | Params: n=3, skip=2, remove_punctuation=True, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8275 | Params: n=3, skip=2, remove_punctuation=True, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.8320 | Params: n=3, skip=2, remove_punctuation=True, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.9000 | Params: n=3, skip=2, remove_punctuation=True, remove_stopwords=False, apply_weighting=False\n",
      "F1-score: 0.8574 | Params: n=3, skip=2, remove_punctuation=False, remove_stopwords=True, apply_weighting=True\n",
      "F1-score: 0.8985 | Params: n=3, skip=2, remove_punctuation=False, remove_stopwords=True, apply_weighting=False\n",
      "F1-score: 0.8891 | Params: n=3, skip=2, remove_punctuation=False, remove_stopwords=False, apply_weighting=True\n",
      "F1-score: 0.8987 | Params: n=3, skip=2, remove_punctuation=False, remove_stopwords=False, apply_weighting=False\n",
      "\n",
      "Best F1-score: 0.9066442388561816\n",
      "Best Parameters: {'n': 2, 'skip': 1, 'remove_punctuation': True, 'remove_stopwords': True, 'apply_weighting': False}\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el Grid Search\n",
    "grid_search('../Datos/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A partir del Grid Search se identificó que el mejor modelo es un **2-skip-1-grama** actuando sobre textos **sin signos de puntuación**, **sin stopwords** y **con weights de 1 y -1** para los n-gramas apareciendo en textos positivos y negativos, respectivamente.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para obtener las otras métricas (matriz de confusión, accuracy, recall y precision) de un modelo específico y con los datos siendo sometidos a un preprocesamiento determinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar el modelo bajo otras métricas\n",
    "def evaluate_model(file_path, n, skip, remove_punctuation, remove_stopwords, apply_weighting):\n",
    "    # Cargar y preparar los datos\n",
    "    train_data, test_data = load_and_prepare_data(file_path)\n",
    "    train_data['Text'] = train_data['Text'].apply(lambda x: clean_text(x, remove_punctuation=remove_punctuation, remove_stopwords=remove_stopwords))\n",
    "    test_data['Text'] = test_data['Text'].apply(lambda x: clean_text(x, remove_punctuation=remove_punctuation, remove_stopwords=remove_stopwords))\n",
    "    \n",
    "    # Crear subgrupos de entrenamiento: positivos (Label=1) y negativos (Label=0)\n",
    "    positive_texts = train_data[train_data['Label'] == 1]['Text']\n",
    "    negative_texts = train_data[train_data['Label'] == 0]['Text']\n",
    "    \n",
    "    \n",
    "    # Obtener las frecuencias netas de los n-gramas en el corpus\n",
    "    ngram_values = apply_class_weighting(positive_texts, negative_texts, n, skip, apply_weighting=apply_weighting)\n",
    "\n",
    "    # Predecir la polaridad de los textos en el conjunto de prueba\n",
    "    y_pred = predict_polarity(test_data, ngram_values, n=n, skip=skip)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    y_test = test_data['Label']\n",
    "    \n",
    "    # Mostrar las métricas\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1-score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2-skip-1-grama**\n",
    "\n",
    "- **sin signos de puntuación**\n",
    "\n",
    "- **sin stopwords**\n",
    "\n",
    "- **weight = 1 en textos positivos**\n",
    "\n",
    "- **weight = -1 en textos negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8326\n",
      "Precision: 0.8318\n",
      "Recall: 0.9963\n",
      "F1-score: 0.9066\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 13 109]\n",
      " [  2 539]]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la evaluación del modelo\n",
    "evaluate_model('../Datos/train.csv', n=2, skip=1, remove_punctuation=True, remove_stopwords=True, apply_weighting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2-skip-2-grama**\n",
    "\n",
    "- **sin signos de puntuación**\n",
    "\n",
    "- **sin stopwords**\n",
    "\n",
    "- **weight = 1 en textos positivos**\n",
    "\n",
    "- **weight = -1 en textos negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8311\n",
      "Precision: 0.8295\n",
      "Recall: 0.9982\n",
      "F1-score: 0.9060\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 11 111]\n",
      " [  1 540]]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la evaluación del modelo\n",
    "evaluate_model('../Datos/train.csv', n=2, skip=2, remove_punctuation=True, remove_stopwords=True, apply_weighting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **0-skip-3-grama**\n",
    "\n",
    "- **con signos de puntuación**\n",
    "\n",
    "- **con stopwords**\n",
    "\n",
    "- **weight = 1 en textos positivos**\n",
    "\n",
    "- **weight = -1 en textos negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8190\n",
      "Precision: 0.8194\n",
      "Recall: 0.9982\n",
      "F1-score: 0.9000\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[  3 119]\n",
      " [  1 540]]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la evaluación del modelo\n",
    "evaluate_model('../Datos/train.csv', n=3, skip=0, remove_punctuation=False, remove_stopwords=False, apply_weighting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3-skip-2-grama**\n",
    "\n",
    "- **sin signos de puntuación**\n",
    "\n",
    "- **con stopwords**\n",
    "\n",
    "- **weight = 1 en textos positivos**\n",
    "\n",
    "- **weight = -1 en textos negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8190\n",
      "Precision: 0.8194\n",
      "Recall: 0.9982\n",
      "F1-score: 0.9000\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[  3 119]\n",
      " [  1 540]]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la evaluación del modelo\n",
    "evaluate_model('../Datos/train.csv', n=3, skip=2, remove_punctuation=True, remove_stopwords=False, apply_weighting=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
